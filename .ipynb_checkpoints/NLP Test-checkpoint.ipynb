{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',1000)\n",
    "from lxml import objectify\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer      \n",
    "\n",
    "\n",
    "#Required packages from nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV file or create from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    general_tweets_corpus_train = pd.read_csv('datasets/csv/general-tweets-train-tagged.csv', encoding='utf-8')\n",
    "except:\n",
    "    xml = objectify.parse(open('datasets/xml/general-tweets-train-tagged.xml'))\n",
    "    #sample tweet object\n",
    "    root = xml.getroot()\n",
    "    general_tweets_corpus_train = pd.DataFrame(columns=('content', 'polarity', 'agreement'))\n",
    "    tweets = root.getchildren()\n",
    "    for i in range(0,len(tweets)):\n",
    "        tweet = tweets[i]\n",
    "        row = dict(zip(['content', 'polarity', 'agreement'], \n",
    "                       [tweet.content.text, tweet.sentiments.polarity.value.text, \n",
    "                        tweet.sentiments.polarity.type.text]))\n",
    "        row_s = pd.Series(row)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_train = general_tweets_corpus_train.append(row_s)\n",
    "    general_tweets_corpus_train.to_csv('datasets/csv/general-tweets-train-tagged.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>Opel ha sido, es y será empresa estratégica para #Aragón. El éxito d esta planta contribuirá en gran medida al éxito d la Comunidad Autónoma</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>RT @miabuelasabia: Haz tu vida como hacen los pulmones, quédate con lo bueno y dejar ir lo que no es necesario.</td>\n",
       "      <td>P</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Curiosidad del insomne: si alguien conocía desde 2007 operaciones irregulares de Urdangarin, ¿no estaba obligado a denunciarlas?</td>\n",
       "      <td>N+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>#yeswespainISDIFFERENT BCNA!!!;) vamosssss!!!;)</td>\n",
       "      <td>P</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>La presidenta @mdcospedal cumple. El nuevo IRPF de Cospedal http://t.co/Ngii4vS2 vía @eldigitalcastillalamancha</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           content  \\\n",
       "5670  Opel ha sido, es y será empresa estratégica para #Aragón. El éxito d esta planta contribuirá en gran medida al éxito d la Comunidad Autónoma   \n",
       "3196                               RT @miabuelasabia: Haz tu vida como hacen los pulmones, quédate con lo bueno y dejar ir lo que no es necesario.   \n",
       "779               Curiosidad del insomne: si alguien conocía desde 2007 operaciones irregulares de Urdangarin, ¿no estaba obligado a denunciarlas?   \n",
       "3512                                                                                               #yeswespainISDIFFERENT BCNA!!!;) vamosssss!!!;)   \n",
       "5108                               La presidenta @mdcospedal cumple. El nuevo IRPF de Cospedal http://t.co/Ngii4vS2 vía @eldigitalcastillalamancha   \n",
       "\n",
       "     polarity  agreement  \n",
       "5670       P+  AGREEMENT  \n",
       "3196        P  AGREEMENT  \n",
       "779        N+  AGREEMENT  \n",
       "3512        P  AGREEMENT  \n",
       "5108       P+  AGREEMENT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus = pd.concat([general_tweets_corpus_train])\n",
    "tweets_corpus = tweets_corpus.query('agreement != \"DISAGREEMENT\" and polarity != \"NONE\"')\n",
    "tweets_corpus = tweets_corpus[-tweets_corpus.content.str.contains('^http.*$')]\n",
    "tweets_corpus.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    general_tweets_corpus_test = pd.read_csv('datasets/csv/general-tweets-test1k.csv')#, encoding='utf-8')\n",
    "except:\n",
    "    xml = objectify.parse(open('datasets/xml/general-tweets-test1k.xml'))\n",
    "    #sample tweet object\n",
    "    root = xml.getroot()\n",
    "    general_tweets_corpus_test = pd.DataFrame(columns=('content', 'polarity'))\n",
    "    tweets = root.getchildren()\n",
    "    for i in range(0,len(tweets)):\n",
    "        tweet = tweets[i]\n",
    "        row = dict(zip(['content'], [tweet.content.text]))\n",
    "        row_s = pd.Series(row)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_test = general_tweets_corpus_test.append(row_s)\n",
    "    general_tweets_corpus_test.to_csv('datasets/csv/general-tweets-test1k.csv', index=False)#, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Si si, siempre es eso...Valenciano: La acusación contra el hijo de Chaves es otra campaña contra él http://t.co/gEiGEzHg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>En la radio están poniendo a Glenn Medeiros o es que he hecho flashback...? #EncimaMeLaSe #AdolescenciaDificil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>“@FelipeAlcarazM: Volved a los camarotes, gritó el capitán Rajoy, esto lo arreglamos entre unos pocos.”</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Alierta agradece el impulso del gobierno para fomentar la internacionalización empresarial @TelediarioInter 20:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Se rumorea que la tardanza en conocer el resultado de la votación del #17congresoPP es xq Rajoy ha salido reelegido por un 102% ;)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                content  \\\n",
       "283            Si si, siempre es eso...Valenciano: La acusación contra el hijo de Chaves es otra campaña contra él http://t.co/gEiGEzHg   \n",
       "957                      En la radio están poniendo a Glenn Medeiros o es que he hecho flashback...? #EncimaMeLaSe #AdolescenciaDificil   \n",
       "380                             “@FelipeAlcarazM: Volved a los camarotes, gritó el capitán Rajoy, esto lo arreglamos entre unos pocos.”   \n",
       "405                   Alierta agradece el impulso del gobierno para fomentar la internacionalización empresarial @TelediarioInter 20:30   \n",
       "621  Se rumorea que la tardanza en conocer el resultado de la votación del #17congresoPP es xq Rajoy ha salido reelegido por un 102% ;)   \n",
       "\n",
       "     polarity  \n",
       "283       NaN  \n",
       "957       NaN  \n",
       "380       NaN  \n",
       "405       NaN  \n",
       "621       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test = pd.concat([general_tweets_corpus_test])\n",
    "\n",
    "tweets_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tagged_tweets_corpus_test = pd.read_csv('datasets/csv/general-tweets-test1k-tagged.csv', encoding='utf-8')\n",
    "except:\n",
    "\n",
    "    from lxml import objectify\n",
    "    xml = objectify.parse(open('datasets/xml/general-tweets-test1k-tagged.xml'))\n",
    "    #sample tweet object\n",
    "    root = xml.getroot()\n",
    "    tagged_tweets_corpus_test = pd.DataFrame(columns=('content', 'polarity'))\n",
    "    tweets = root.getchildren()\n",
    "    for i in range(0,len(tweets)):\n",
    "        tweet = tweets[i]\n",
    "        row = dict(zip(['content', 'polarity', 'agreement'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "        row_s = pd.Series(row)\n",
    "        row_s.name = i\n",
    "        tagged_tweets_corpus_test = tagged_tweets_corpus_test.append(row_s)\n",
    "    tagged_tweets_corpus_test.to_csv('datasets/csv/general-tweets-test1k-tagged.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>;-))) gracias RT @JRSMMII: @mariviromero Desde todos los rincones de España, lucharemos con ello.Yo me pienso ofrecer de Interventor. ;)</td>\n",
       "      <td>P+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Esta es una muy muy mala noticia. El pluralismo pierde una voz genuina y honrada. Cierra el diario 'Público' http://t.co/bp7THNBN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Con el año nuevo habrá nuevo Presupuesto de PP+IU. Y con él nuevas responsabilidades para unos y otros.</td>\n",
       "      <td>P+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Entre 2008 y 2010 Andalucía redujo gasto no financiero en un 7,5%, sin recortar derechos. Resto CCAA lo aumentaron 2,5%. (datos MEH)</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>La prima de riesgo de Portugal se dispara hasta los 1.241 puntos base.Totalmente insensato!</td>\n",
       "      <td>N+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      content  \\\n",
       "205  ;-))) gracias RT @JRSMMII: @mariviromero Desde todos los rincones de España, lucharemos con ello.Yo me pienso ofrecer de Interventor. ;)   \n",
       "662         Esta es una muy muy mala noticia. El pluralismo pierde una voz genuina y honrada. Cierra el diario 'Público' http://t.co/bp7THNBN   \n",
       "98                                    Con el año nuevo habrá nuevo Presupuesto de PP+IU. Y con él nuevas responsabilidades para unos y otros.   \n",
       "251      Entre 2008 y 2010 Andalucía redujo gasto no financiero en un 7,5%, sin recortar derechos. Resto CCAA lo aumentaron 2,5%. (datos MEH)   \n",
       "344                                               La prima de riesgo de Portugal se dispara hasta los 1.241 puntos base.Totalmente insensato!   \n",
       "\n",
       "    polarity  \n",
       "205       P+  \n",
       "662        N  \n",
       "98        P+  \n",
       "251        N  \n",
       "344       N+  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tagged = pd.concat([tagged_tweets_corpus_test])\n",
    "tweets_tagged = tweets_tagged.query('polarity != \"NONE\"')\n",
    "diff = np.setdiff1d(tweets_test.index.values, tweets_tagged.index.values)\n",
    "\n",
    "tweets_test = tweets_test.drop(diff)\n",
    "tweets_tagged.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Stems Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stem: Cut word in root (wait: wait, waited: wait, waiting: wait)\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#Each word is a token\n",
    "def tokenize(text):\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stopwords: Empty word (i.e articles)\n",
    "\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "\n",
    "#Non Words: Symbols and Numbers\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model (Linear SVM) and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.53994\n",
      "0    0.46006\n",
      "Name: polarity_bin, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>agreement</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Rubalcaba le pregunta a Rajoy, y con razón, cuándo va a anunciar las malas noticias.</td>\n",
       "      <td>N</td>\n",
       "      <td>AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Empieza el acto de homenaje a la Constitución con el próximo Presidente del Gobierno. #vivalaconstitucion  http://t.co/gRTAQmVu</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>Desde hace 2meses,Gobierno trabaja en modificación C.Penal para equiparar violencia de los antisistema con la callejera ligada al terrorismo</td>\n",
       "      <td>NEU</td>\n",
       "      <td>AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           content  \\\n",
       "950                                                           Rubalcaba le pregunta a Rajoy, y con razón, cuándo va a anunciar las malas noticias.   \n",
       "224                Empieza el acto de homenaje a la Constitución con el próximo Presidente del Gobierno. #vivalaconstitucion  http://t.co/gRTAQmVu   \n",
       "6838  Desde hace 2meses,Gobierno trabaja en modificación C.Penal para equiparar violencia de los antisistema con la callejera ligada al terrorismo   \n",
       "\n",
       "     polarity  agreement  polarity_bin  \n",
       "950         N  AGREEMENT             0  \n",
       "224        P+  AGREEMENT             1  \n",
       "6838      NEU  AGREEMENT             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarizing\n",
    "\n",
    "tweets_corpus['polarity_bin'] = 0\n",
    "index = tweets_corpus.polarity.isin(['P', 'P+'])\n",
    "tweets_corpus.polarity_bin.loc[index] = 1\n",
    "print tweets_corpus.polarity_bin.value_counts(normalize=True)\n",
    "\n",
    "tweets_test['polarity_bin'] = 0\n",
    "\n",
    "tweets_tagged['polarity_bin'] = 0\n",
    "index = tweets_tagged.polarity.isin(['P', 'P+'])\n",
    "tweets_tagged.polarity_bin.loc[index] = 1\n",
    "tweets_tagged.polarity_bin.value_counts(normalize=True)\n",
    "\n",
    "y = tweets_tagged.polarity_bin.values\n",
    "\n",
    "tweets_corpus.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', LinearSVC()),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'cls__C': (0.2, 0.5, 0.7),\n",
    "    'cls__loss': ('hinge', 'squared_hinge'),\n",
    "    'cls__max_iter': (500, 1000)\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1 , scoring='roc_auc')\n",
    "grid_search.fit(tweets_corpus.content, tweets_corpus.polarity_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 50,\n",
    "            max_df = 1.9,\n",
    "            ngram_range=(1, 1),\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', LinearSVC(C=.2, loss='squared_hinge',max_iter=1000,multi_class='ovr',\n",
    "             random_state=None,\n",
    "             penalty='l2',\n",
    "             tol=0.0001\n",
    "             )),\n",
    "])\n",
    "\n",
    "pipeline.fit(tweets_corpus.content, tweets_corpus.polarity_bin)\n",
    "tweets_test['polarity_bin'] = pipeline.predict(tweets_test.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68227481108362864"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline.fit(X_train.content, X_train.polarity_bin)\n",
    "\n",
    "scores = cross_val_score(p, tweets_corpus.content, tweets_corpus.polarity_bin, cv=5)\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71975497702909652"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = tweets_test.polarity_bin.values\n",
    "result = np.abs(y_t - y)\n",
    "np.bincount(result)[0]/float(result.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
